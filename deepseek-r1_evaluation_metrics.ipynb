{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a39708a-aae3-4d5f-bd76-e32144573bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import evaluate\n",
    "from bert_score import score as bertscore\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb6f62b-b25f-4596-a597-7a845f488621",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_r1_df = pd.read_csv(\"MIMIC-IV-deepseek-r1-summaries.csv\")\n",
    "reference_df = pd.read_csv(\"bhc_reference_summaries(deepseek-r1).csv\")\n",
    "\n",
    "df = pd.merge(deepseek_r1_df, reference_df, on=\"note_id\")\n",
    "generated = df['summary'].fillna(\"\").tolist()\n",
    "reference = df['target'].fillna(\"\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b1e8f8-5591-426c-a126-8a1c93d7ecf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.27k/6.27k [00:00<?, ?B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š ROUGE Scores:\n",
      "ROUGE1: 0.3220\n",
      "ROUGE2: 0.0740\n",
      "ROUGEL: 0.1417\n",
      "ROUGELSUM: 0.2082\n"
     ]
    }
   ],
   "source": [
    "### 1. ROUGE Score\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "rouge_result = rouge.compute(predictions=generated, references=reference)\n",
    "\n",
    "print(\"\\nðŸ“Š ROUGE Scores:\")\n",
    "for k, v in rouge_result.items():\n",
    "    print(f\"{k.upper()}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c074ab-a9f2-4b9d-af6a-73ae30a78245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š BLEU Score (average over 1000 rows):\n",
      "BLEU: 0.0235\n"
     ]
    }
   ],
   "source": [
    "### 2. BLEU (average over all rows)\n",
    "smoothie = SmoothingFunction().method4\n",
    "bleu_scores = [\n",
    "    sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie)\n",
    "    for ref, pred in zip(reference, generated)\n",
    "]\n",
    "bleu_avg = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "print(\"\\nðŸ“Š BLEU Score (average over 1000 rows):\")\n",
    "print(f\"BLEU: {bleu_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3424bde2-5aff-4d85-90c9-cb7e73d3257b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:18<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 31.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 18.68 seconds, 53.54 sentences/sec\n",
      "\n",
      "ðŸ“Š BERTScore:\n",
      "Precision: 0.8152\n",
      "Recall:    0.8194\n",
      "F1 Score:  0.8172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### 3. BERTScore\n",
    "P, R, F1 = bertscore(generated, reference, lang=\"en\", verbose=True)\n",
    "bert_avg = {\n",
    "    \"precision\": P.mean().item(),\n",
    "    \"recall\": R.mean().item(),\n",
    "    \"f1\": F1.mean().item()\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ“Š BERTScore:\")\n",
    "print(f\"Precision: {bert_avg['precision']:.4f}\")\n",
    "print(f\"Recall:    {bert_avg['recall']:.4f}\")\n",
    "print(f\"F1 Score:  {bert_avg['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b2b57-4dc6-474d-bd1f-0b9ee87f445e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
